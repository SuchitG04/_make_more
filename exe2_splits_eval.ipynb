{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1544c5a7-20bc-41b9-bc75-60fbdcacc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5eb7d11-98a6-47ac-86b9-5436b52afcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"./names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdf9e6f-2c51-477a-9ad7-a044b46cac6a",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7f9610-1c52-40e6-9141-d501683009cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, temp_words = train_test_split(words, train_size=0.8, random_state=42)\n",
    "dev_words, test_words = train_test_split(temp_words, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160d91b3-4d8d-4fa9-9fd0-53cb7ba5911b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25626, 3203, 3204)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_words), len(dev_words), len(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc7e25-24a0-4a87-bcf0-c3d587e01a80",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c170ace9-e8ff-4521-933f-1a6b3084d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chars = sorted(list(set(''.join(train_words))))\n",
    "N_b = torch.zeros((27, 27), dtype=torch.int32)\n",
    "stoi = {s:i+1 for i,s in enumerate(train_chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "# model smoothing\n",
    "N_b += 3\n",
    "\n",
    "# \"training\"\n",
    "for w in train_words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    N_b[ix1, ix2] += 1\n",
    "\n",
    "P = N_b.float()\n",
    "P /= P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d46b002c-0168-498b-b79a-7cb2e9b47aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n",
      "nn.\n",
      "kohin.\n",
      "tolian.\n",
      "juwe.\n",
      "ksahnaauranilevias.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    p = P[ix]\n",
    "    ix = torch.multinomial(p, num_samples=1, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a24dc-8d14-477b-9aa1-639116259e82",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a627615d-02dc-44da-b7ab-6cd44e455795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train split scores---\n",
      "nll=tensor(448501.8438)\n",
      "nll/n=tensor(2.4576)\n"
     ]
    }
   ],
   "source": [
    "n = 0; log_likelihood = 0.0\n",
    "for w in train_words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    prob = P[ix1, ix2]\n",
    "    log_prob = torch.log(prob)\n",
    "    log_likelihood += log_prob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Train split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3aeda7-7944-467b-aebf-aacf9a37ddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Dev split scores---\n",
      "nll=tensor(56075.5391)\n",
      "nll/n=tensor(2.4506)\n"
     ]
    }
   ],
   "source": [
    "n = 0; log_likelihood = 0.0\n",
    "for w in dev_words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    prob = P[ix1, ix2]\n",
    "    log_prob = torch.log(prob)\n",
    "    log_likelihood += log_prob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Dev split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3f2964-9daa-4984-a337-c3c8b188586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test split scores---\n",
      "nll=tensor(56024.1211)\n",
      "nll/n=tensor(2.4608)\n"
     ]
    }
   ],
   "source": [
    "n = 0; log_likelihood = 0.0\n",
    "for w in test_words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    prob = P[ix1, ix2]\n",
    "    log_prob = torch.log(prob)\n",
    "    log_likelihood += log_prob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Test split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82b958-28ba-49cb-9364-5776809709b1",
   "metadata": {},
   "source": [
    "Inuitively, the loss (average negative log likelihood, in other words) should have been lesser on the training dataset, but it turns out here that dev split loss is lesser than the train split loss. In order to keep myself sane, I attribute this \"anomaly\" to the random seed 42 ;p\n",
    "\n",
    "I'm pretty sure that I would get the expected result if I were to choose any other seed.\n",
    "\n",
    "After trying out 2 different seeds, I did get the expected result of the training loss being higher than the dev loss (and equal to the test loss :/) with one of the seeds (69). This inconsistency might be due to the dataset being small or other statistical stuff I don't know about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d127cf25-ce07-4c20-a437-018b7063ffbd",
   "metadata": {},
   "source": [
    "## Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5864850a-fb2f-43ba-b6b1-14ff7075aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_chars = set()\n",
    "for c1 in train_chars+[\".\"]:\n",
    "  for c2 in train_chars+[\".\"]:\n",
    "    two_chars.add(c1+c2)\n",
    "\n",
    "two_chars = sorted(list(two_chars))\n",
    "\n",
    "stoi2 = {s:i for i,s in enumerate(two_chars)}\n",
    "itos2 = {i:s for i,s in enumerate(two_chars)}\n",
    "\n",
    "N_t = torch.zeros((729, 27), dtype=torch.int32)\n",
    "\n",
    "# model smoothing\n",
    "N_t += 3\n",
    "\n",
    "# \"training\"\n",
    "for w in train_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    N_t[ix1, ix2] += 1\n",
    "\n",
    "P = N_t.float()\n",
    "P /= P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c67494-ea08-42bc-9129-cbfc9fed5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".luwjdvdianasid.\n",
      ".ulexay.\n",
      ".adin.\n",
      ".vairritoper.\n",
      ".maree.\n",
      ".viameiaurinileniassdbduinrwibtlyssiyanaylarte.\n",
      ".unvmumthyfodtumj.\n",
      ".nonnslenarsani.\n",
      ".rose.\n",
      ".yae.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(10):\n",
    "  ix = 1\n",
    "  out = [\".\"]\n",
    "  while True:\n",
    "    if ix != 1:\n",
    "      ix = stoi2[''.join(out[-2:])]\n",
    "    p = P[ix]\n",
    "    ix = torch.multinomial(p, num_samples=1, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if out[-1][-1] == \".\":\n",
    "      break\n",
    "  \n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9224433-c182-46db-ab03-8c79d429998e",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af21ea15-d155-4a7f-95f6-ed3ae0752384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train split scores---\n",
      "nll=tensor(336548.5000)\n",
      "nll/n=tensor(2.1454)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "log_likelihood = 0.0\n",
    "for w in train_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Train split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0b5063-c3c8-4e7a-be27-e9b0fb8a0424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Dev split scores---\n",
      "nll=tensor(42471.5547)\n",
      "nll/n=tensor(2.1582)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "log_likelihood = 0.0\n",
    "for w in dev_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Dev split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc42ea9c-60ad-41e6-aab1-cdc0e6f60af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test split scores---\n",
      "nll=tensor(42595.9688)\n",
      "nll/n=tensor(2.1774)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "log_likelihood = 0.0\n",
    "for w in test_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Test split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ab97b-274e-48a0-8544-320909358817",
   "metadata": {},
   "source": [
    "For the trigram model, the scores are as expected - train loss is higher than dev and test loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c9a7a-a952-40ff-817f-dc703f6a63f5",
   "metadata": {},
   "source": [
    "## Bigram using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db87c088-8f67-4d8a-a443-0e3026a3f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364bf64a-1ece-4b60-b304-1b3a0c6bace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "for w in train_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2 in zip(chs,chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)    \n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "# initialize neural net\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf3bf5bd-ee21-4f4a-b5e2-0a7a1ca1a056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7672510147094727\n",
      "3.238084077835083\n",
      "3.015225887298584\n",
      "2.8891587257385254\n",
      "2.8101205825805664\n",
      "2.7558672428131104\n",
      "2.7155206203460693\n",
      "2.684164524078369\n",
      "2.6589431762695312\n",
      "2.638404369354248\n",
      "2.6213760375976562\n",
      "2.6071972846984863\n",
      "2.595180034637451\n",
      "2.584972381591797\n",
      "2.5761351585388184\n",
      "2.5684926509857178\n",
      "2.561751365661621\n",
      "2.555835008621216\n",
      "2.5505361557006836\n",
      "2.545834541320801\n",
      "2.5415725708007812\n",
      "2.5377626419067383\n",
      "2.53427791595459\n",
      "2.531146287918091\n",
      "2.528259038925171\n",
      "2.5256547927856445\n",
      "2.5232367515563965\n",
      "2.5210483074188232\n",
      "2.5190019607543945\n",
      "2.5171456336975098\n",
      "2.515397310256958\n",
      "2.513808250427246\n",
      "2.512301445007324\n",
      "2.510929584503174\n",
      "2.50961971282959\n",
      "2.5084259510040283\n",
      "2.50727915763855\n",
      "2.5062332153320312\n",
      "2.5052218437194824\n",
      "2.5042994022369385\n",
      "2.503401279449463\n",
      "2.502582311630249\n",
      "2.5017807483673096\n",
      "2.5010502338409424\n",
      "2.5003304481506348\n",
      "2.4996755123138428\n",
      "2.49902606010437\n",
      "2.498436450958252\n",
      "2.4978482723236084\n",
      "2.4973151683807373\n",
      "2.4967801570892334\n",
      "2.4962964057922363\n",
      "2.4958083629608154\n",
      "2.495368719100952\n",
      "2.4949216842651367\n",
      "2.494520664215088\n",
      "2.494109869003296\n",
      "2.4937431812286377\n",
      "2.4933652877807617\n",
      "2.4930291175842285\n",
      "2.492680549621582\n",
      "2.4923720359802246\n",
      "2.4920494556427\n",
      "2.4917657375335693\n",
      "2.491466760635376\n",
      "2.4912052154541016\n",
      "2.4909276962280273\n",
      "2.4906864166259766\n",
      "2.4904282093048096\n",
      "2.4902050495147705\n",
      "2.489964246749878\n",
      "2.489758253097534\n",
      "2.4895334243774414\n",
      "2.489342212677002\n",
      "2.4891321659088135\n",
      "2.488954544067383\n",
      "2.4887583255767822\n",
      "2.488593101501465\n",
      "2.4884085655212402\n",
      "2.488255023956299\n",
      "2.488081932067871\n",
      "2.4879391193389893\n",
      "2.487776279449463\n",
      "2.487642765045166\n",
      "2.4874894618988037\n",
      "2.487365245819092\n",
      "2.487220287322998\n",
      "2.4871041774749756\n",
      "2.4869675636291504\n",
      "2.4868597984313965\n",
      "2.486729621887207\n",
      "2.486628532409668\n",
      "2.4865059852600098\n",
      "2.4864110946655273\n",
      "2.4862945079803467\n",
      "2.4862060546875\n",
      "2.486095428466797\n",
      "2.4860122203826904\n",
      "2.4859070777893066\n",
      "2.4858293533325195\n",
      "2.485729455947876\n",
      "2.485656261444092\n",
      "2.485560655593872\n",
      "2.48549222946167\n",
      "2.485401153564453\n",
      "2.4853367805480957\n",
      "2.4852495193481445\n",
      "2.4851889610290527\n",
      "2.4851059913635254\n",
      "2.48504900932312\n",
      "2.4849693775177\n",
      "2.4849154949188232\n",
      "2.48483943939209\n",
      "2.4847891330718994\n",
      "2.4847159385681152\n",
      "2.484668493270874\n",
      "2.484598398208618\n",
      "2.484553813934326\n",
      "2.4844858646392822\n",
      "2.4844441413879395\n",
      "2.4843790531158447\n",
      "2.484339475631714\n",
      "2.4842770099639893\n",
      "2.4842395782470703\n",
      "2.4841794967651367\n",
      "2.4841442108154297\n",
      "2.484086275100708\n",
      "2.484053373336792\n",
      "2.483997106552124\n",
      "2.4839658737182617\n",
      "2.4839119911193848\n",
      "2.4838826656341553\n",
      "2.483829975128174\n",
      "2.483802318572998\n",
      "2.4837517738342285\n",
      "2.4837260246276855\n",
      "2.4836766719818115\n",
      "2.483652114868164\n",
      "2.483604669570923\n",
      "2.483581304550171\n",
      "2.4835355281829834\n",
      "2.483513832092285\n",
      "2.483469247817993\n",
      "2.4834487438201904\n",
      "2.483405113220215\n",
      "2.483386278152466\n",
      "2.4833438396453857\n",
      "2.483325719833374\n",
      "2.4832849502563477\n",
      "2.4832680225372314\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for _ in range(150):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float()\n",
    "  logits = xenc @ W\n",
    "  counts = logits.exp()\n",
    "  probs = counts / counts.sum(1, keepdim=True)\n",
    "  loss = -probs[torch.arange(xs.nelement()), ys].log().mean() + 0.01*(W**2).mean()\n",
    "\n",
    "  print(loss.item())\n",
    "\n",
    "  # backward pass\n",
    "  W.grad = None\n",
    "  loss.backward()\n",
    "  with torch.no_grad():\n",
    "    W.data += -75 * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19857236-f4c5-4963-b2be-7583ecc89bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "prelay.\n",
      "a.\n",
      "nn.\n",
      "kohin.\n",
      "tolia.\n",
      "s.\n",
      "tee.\n",
      "ksahnaauranilevias.\n"
     ]
    }
   ],
   "source": [
    "# sampling from the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9643d62-65cb-477c-815c-e4c3175ed314",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7c8254b-4677-4c62-9849-b575b2bf24cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train split scores---\n",
      "nll=tensor(2.4652, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "avg_log_likelihood = probs[torch.arange(xs.nelement()), ys].log().mean()\n",
    "      \n",
    "nll = -avg_log_likelihood\n",
    "print(\"---Train split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c80b52bc-fdda-4434-9e6d-3fb6e029dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Dev split scores---\n",
      "nll=tensor(2.4578, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dev_xs, dev_ys = [], []\n",
    "for w in dev_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2 in zip(chs,chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    dev_xs.append(ix1)\n",
    "    dev_ys.append(ix2)\n",
    "\n",
    "dev_xs = torch.tensor(dev_xs)    \n",
    "dev_ys = torch.tensor(dev_ys)\n",
    "\n",
    "xenc = F.one_hot(dev_xs, num_classes=27).float()\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "avg_log_likelihood = probs[torch.arange(dev_xs.nelement()), dev_ys].log().mean()\n",
    "      \n",
    "nll = -avg_log_likelihood\n",
    "print(\"---Dev split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f462e8e-b640-4408-aa40-0f638fb4320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test split scores---\n",
      "nll=tensor(2.4680, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_xs, test_ys = [], []\n",
    "for w in test_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2 in zip(chs,chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    test_xs.append(ix1)\n",
    "    test_ys.append(ix2)\n",
    "\n",
    "test_xs = torch.tensor(test_xs)    \n",
    "test_ys = torch.tensor(test_ys)\n",
    "\n",
    "xenc = F.one_hot(test_xs, num_classes=27).float()\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "avg_log_likelihood = probs[torch.arange(test_xs.nelement()), test_ys].log().mean()\n",
    "      \n",
    "nll = -avg_log_likelihood\n",
    "print(\"---Test split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e6949-3014-4f8a-bcb7-4e228e3cb45d",
   "metadata": {},
   "source": [
    "## Trigram using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5d59c23-73ce-4618-a793-ca46049ae338",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_t, ys_t = [], []\n",
    "for w in train_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    xs_t.append(ix1)\n",
    "    ys_t.append(ix2)\n",
    "\n",
    "xs_t = torch.tensor(xs_t)\n",
    "ys_t = torch.tensor(ys_t)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((729, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a8fd855-5160-4934-997f-0f9174a4b132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7336504459381104\n",
      "3.6212451457977295\n",
      "3.519554376602173\n",
      "3.4285521507263184\n",
      "3.3480427265167236\n",
      "3.277346134185791\n",
      "3.215322494506836\n",
      "3.160595417022705\n",
      "3.111837863922119\n",
      "3.0679633617401123\n",
      "3.028154134750366\n",
      "2.991804599761963\n",
      "2.9584553241729736\n",
      "2.927744150161743\n",
      "2.8993759155273438\n",
      "2.873103380203247\n",
      "2.848714590072632\n",
      "2.8260245323181152\n",
      "2.804870367050171\n",
      "2.7851061820983887\n",
      "2.766599655151367\n",
      "2.749232769012451\n",
      "2.732896566390991\n",
      "2.7174947261810303\n",
      "2.7029411792755127\n",
      "2.6891579627990723\n",
      "2.676077365875244\n",
      "2.663638114929199\n",
      "2.651787281036377\n",
      "2.640477418899536\n",
      "2.629666566848755\n",
      "2.619316577911377\n",
      "2.6093943119049072\n",
      "2.599870204925537\n",
      "2.59071683883667\n",
      "2.5819106101989746\n",
      "2.5734288692474365\n",
      "2.5652520656585693\n",
      "2.5573620796203613\n",
      "2.5497424602508545\n",
      "2.5423777103424072\n",
      "2.5352542400360107\n",
      "2.5283591747283936\n",
      "2.5216808319091797\n",
      "2.5152084827423096\n",
      "2.5089316368103027\n",
      "2.502840995788574\n",
      "2.4969279766082764\n",
      "2.491184711456299\n",
      "2.4856033325195312\n",
      "2.4801769256591797\n",
      "2.47489857673645\n",
      "2.469762086868286\n",
      "2.4647622108459473\n",
      "2.4598922729492188\n",
      "2.455148220062256\n",
      "2.4505248069763184\n",
      "2.446017026901245\n",
      "2.4416208267211914\n",
      "2.4373319149017334\n",
      "2.4331462383270264\n",
      "2.4290599822998047\n",
      "2.425069570541382\n",
      "2.421172618865967\n",
      "2.4173645973205566\n",
      "2.4136428833007812\n",
      "2.4100046157836914\n",
      "2.406446933746338\n",
      "2.402967691421509\n",
      "2.3995633125305176\n",
      "2.3962321281433105\n",
      "2.392972230911255\n",
      "2.389780282974243\n",
      "2.3866546154022217\n",
      "2.3835930824279785\n",
      "2.380594491958618\n",
      "2.3776559829711914\n",
      "2.3747763633728027\n",
      "2.3719537258148193\n",
      "2.3691861629486084\n",
      "2.3664724826812744\n",
      "2.3638107776641846\n",
      "2.3612003326416016\n",
      "2.3586385250091553\n",
      "2.3561248779296875\n",
      "2.3536579608917236\n",
      "2.35123610496521\n",
      "2.348858594894409\n",
      "2.3465235233306885\n",
      "2.3442301750183105\n",
      "2.341977596282959\n",
      "2.339764356613159\n",
      "2.337589740753174\n",
      "2.3354525566101074\n",
      "2.3333520889282227\n",
      "2.331286668777466\n",
      "2.3292558193206787\n",
      "2.327259063720703\n",
      "2.3252947330474854\n",
      "2.3233625888824463\n",
      "2.3214619159698486\n",
      "2.319591522216797\n",
      "2.317750930786133\n",
      "2.315938949584961\n",
      "2.314155340194702\n",
      "2.312399387359619\n",
      "2.3106701374053955\n",
      "2.308967351913452\n",
      "2.3072903156280518\n",
      "2.305638074874878\n",
      "2.3040101528167725\n",
      "2.302406072616577\n",
      "2.3008251190185547\n",
      "2.299267292022705\n",
      "2.297731637954712\n",
      "2.296217679977417\n",
      "2.294724941253662\n",
      "2.29325270652771\n",
      "2.2918012142181396\n",
      "2.290369749069214\n",
      "2.288957118988037\n",
      "2.2875640392303467\n",
      "2.286189317703247\n",
      "2.2848331928253174\n",
      "2.283494234085083\n",
      "2.2821733951568604\n",
      "2.280869245529175\n",
      "2.2795822620391846\n",
      "2.278311252593994\n",
      "2.2770566940307617\n",
      "2.27581787109375\n",
      "2.274594306945801\n",
      "2.273386001586914\n",
      "2.2721924781799316\n",
      "2.2710139751434326\n",
      "2.2698495388031006\n",
      "2.2686991691589355\n",
      "2.2675621509552\n",
      "2.266439199447632\n",
      "2.265329360961914\n",
      "2.264232635498047\n",
      "2.263148546218872\n",
      "2.2620768547058105\n",
      "2.2610180377960205\n",
      "2.2599706649780273\n",
      "2.2589356899261475\n",
      "2.2579123973846436\n",
      "2.2569005489349365\n",
      "2.2558999061584473\n",
      "2.2549099922180176\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for _ in range(150):\n",
    "  \n",
    "  # forward pass\n",
    "  # xenc = F.one_hot(xs_t, num_classes=729).float()\n",
    "  # logits = xenc @ W\n",
    "  logits = W[xs_t]\n",
    "  counts = logits.exp()\n",
    "  probs = counts / counts.sum(1, keepdim=True)\n",
    "  loss = -probs[torch.arange(xs_t.nelement()), ys_t].log().mean() + 0.01*(W**2).mean()\n",
    "\n",
    "  print(loss.item())\n",
    "\n",
    "  # backward pass\n",
    "  W.grad = None\n",
    "  loss.backward()\n",
    "  with torch.no_grad():\n",
    "    W.data += -75 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "89d3e834-99d8-44b9-b385-3adeefbbe43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".luwjde.\n",
      ".ilyasiz.\n",
      ".ufofyywocnzq.\n",
      ".di.\n",
      ".ritoniabraree.\n",
      ".viameiauriniadvhassdbyainrwibwlassiyanaylartleigvmumtrifoetumj.\n",
      ".nonn.\n",
      ".lenariani.\n",
      ".rose.\n",
      ".yae.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(10):\n",
    "  ix = 1\n",
    "  out = [\".\"]\n",
    "  while True:\n",
    "    if ix != 1:\n",
    "      ix = stoi2[''.join(out[-2:])]\n",
    "    logits = W[ix]\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum() \n",
    "      \n",
    "    ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if out[-1][-1] == \".\":\n",
    "      break\n",
    "  \n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c20f30-4e21-4e28-bdfb-ff73a1b13daf",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "acf22828-084c-4b79-8dd6-07e615cbf14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train split scores---\n",
      "nll=tensor(2.2434, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "log_likelihood = 0.0\n",
    "logits = W[xs_t]\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "nll = -probs[torch.arange(xs_t.nelement()), ys_t].log().mean()\n",
    "\n",
    "print(\"---Train split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd48e150-fd34-45ad-94cd-e76386333a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Dev split scores---\n",
      "nll=tensor(2.2487, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dev_xs_t, dev_ys_t = [], []\n",
    "for w in dev_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    dev_xs_t.append(ix1)\n",
    "    dev_ys_t.append(ix2)\n",
    "\n",
    "dev_xs_t = torch.tensor(dev_xs_t)\n",
    "dev_ys_t = torch.tensor(dev_ys_t)\n",
    "\n",
    "logits = W[dev_xs_t]\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "nll = -probs[torch.arange(dev_xs_t.nelement()), dev_ys_t].log().mean()\n",
    "\n",
    "print(\"---Dev split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5c60c35-8fa4-4b2b-8f63-1f51461a2038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test split scores---\n",
      "nll=tensor(2.2715, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_xs_t, test_ys_t = [], []\n",
    "for w in test_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    test_xs_t.append(ix1)\n",
    "    test_ys_t.append(ix2)\n",
    "\n",
    "test_xs_t = torch.tensor(test_xs_t)\n",
    "test_ys_t = torch.tensor(test_ys_t)\n",
    "\n",
    "logits = W[test_xs_t]\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "nll = -probs[torch.arange(test_xs_t.nelement()), test_ys_t].log().mean()\n",
    "\n",
    "print(\"---Test split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed284b-60b9-4e2e-a200-62957a138610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
