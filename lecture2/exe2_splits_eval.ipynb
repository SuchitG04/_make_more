{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1544c5a7-20bc-41b9-bc75-60fbdcacc2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5eb7d11-98a6-47ac-86b9-5436b52afcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"./names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdf9e6f-2c51-477a-9ad7-a044b46cac6a",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c7f9610-1c52-40e6-9141-d501683009cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, temp_words = train_test_split(words, train_size=0.8, random_state=42)\n",
    "dev_words, test_words = train_test_split(temp_words, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160d91b3-4d8d-4fa9-9fd0-53cb7ba5911b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25626, 3203, 3204)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_words), len(dev_words), len(test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc7e25-24a0-4a87-bcf0-c3d587e01a80",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c170ace9-e8ff-4521-933f-1a6b3084d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chars = sorted(list(set(''.join(train_words))))\n",
    "N_b = torch.zeros((27, 27), dtype=torch.int32)\n",
    "stoi = {s:i+1 for i,s in enumerate(train_chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "# model smoothing\n",
    "N_b += 3\n",
    "\n",
    "# \"training\"\n",
    "for w in train_words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    N_b[ix1, ix2] += 1\n",
    "\n",
    "P = N_b.float()\n",
    "P /= P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d46b002c-0168-498b-b79a-7cb2e9b47aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n",
      "nn.\n",
      "kohin.\n",
      "tolian.\n",
      "juwe.\n",
      "ksahnaauranilevias.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    p = P[ix]\n",
    "    ix = torch.multinomial(p, num_samples=1, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a24dc-8d14-477b-9aa1-639116259e82",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a627615d-02dc-44da-b7ab-6cd44e455795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train split scores---\n",
      "nll=tensor(448501.8438)\n",
      "nll/n=tensor(2.4576)\n"
     ]
    }
   ],
   "source": [
    "n = 0; log_likelihood = 0.0\n",
    "for w in train_words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    prob = P[ix1, ix2]\n",
    "    log_prob = torch.log(prob)\n",
    "    log_likelihood += log_prob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Train split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3aeda7-7944-467b-aebf-aacf9a37ddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Dev split scores---\n",
      "nll=tensor(56075.5391)\n",
      "nll/n=tensor(2.4506)\n"
     ]
    }
   ],
   "source": [
    "n = 0; log_likelihood = 0.0\n",
    "for w in dev_words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    prob = P[ix1, ix2]\n",
    "    log_prob = torch.log(prob)\n",
    "    log_likelihood += log_prob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Dev split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3f2964-9daa-4984-a337-c3c8b188586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test split scores---\n",
      "nll=tensor(56024.1211)\n",
      "nll/n=tensor(2.4608)\n"
     ]
    }
   ],
   "source": [
    "n = 0; log_likelihood = 0.0\n",
    "for w in test_words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1,ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    prob = P[ix1, ix2]\n",
    "    log_prob = torch.log(prob)\n",
    "    log_likelihood += log_prob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Test split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82b958-28ba-49cb-9364-5776809709b1",
   "metadata": {},
   "source": [
    "Inuitively, the loss (average negative log likelihood, in other words) should have been lesser on the training dataset, but it turns out here that dev split loss is lesser than the train split loss. In order to keep myself sane, I attribute this \"anomaly\" to the random seed 42 ;p\n",
    "\n",
    "I'm pretty sure that I would get the expected result if I were to choose any other seed.\n",
    "\n",
    "After trying out 2 different seeds, I did get the expected result of the training loss being higher than the dev loss (and equal to the test loss :/) with one of the seeds (69). This inconsistency might be due to the dataset being small or other statistical stuff I don't know about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d127cf25-ce07-4c20-a437-018b7063ffbd",
   "metadata": {},
   "source": [
    "## Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5864850a-fb2f-43ba-b6b1-14ff7075aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_chars = set()\n",
    "for c1 in train_chars+[\".\"]:\n",
    "  for c2 in train_chars+[\".\"]:\n",
    "    two_chars.add(c1+c2)\n",
    "\n",
    "two_chars = sorted(list(two_chars))\n",
    "\n",
    "stoi2 = {s:i for i,s in enumerate(two_chars)}\n",
    "itos2 = {i:s for i,s in enumerate(two_chars)}\n",
    "\n",
    "N_t = torch.zeros((729, 27), dtype=torch.int32)\n",
    "\n",
    "# model smoothing\n",
    "N_t += 3\n",
    "\n",
    "# \"training\"\n",
    "for w in train_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    N_t[ix1, ix2] += 1\n",
    "\n",
    "P = N_t.float()\n",
    "P /= P.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5c67494-ea08-42bc-9129-cbfc9fed5487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".luwjdvdianasid.\n",
      ".ulexay.\n",
      ".adin.\n",
      ".vairritoper.\n",
      ".maree.\n",
      ".viameiaurinileniassdbduinrwibtlyssiyanaylarte.\n",
      ".unvmumthyfodtumj.\n",
      ".nonnslenarsani.\n",
      ".rose.\n",
      ".yae.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for _ in range(10):\n",
    "  ix = 1\n",
    "  out = [\".\"]\n",
    "  while True:\n",
    "    if ix != 1:\n",
    "      ix = stoi2[''.join(out[-2:])]\n",
    "    p = P[ix]\n",
    "    ix = torch.multinomial(p, num_samples=1, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if out[-1][-1] == \".\":\n",
    "      break\n",
    "  \n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9224433-c182-46db-ab03-8c79d429998e",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af21ea15-d155-4a7f-95f6-ed3ae0752384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train split scores---\n",
      "nll=tensor(336548.5000)\n",
      "nll/n=tensor(2.1454)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "log_likelihood = 0.0\n",
    "for w in train_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Train split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0b5063-c3c8-4e7a-be27-e9b0fb8a0424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Dev split scores---\n",
      "nll=tensor(42471.5547)\n",
      "nll/n=tensor(2.1582)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "log_likelihood = 0.0\n",
    "for w in dev_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Dev split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc42ea9c-60ad-41e6-aab1-cdc0e6f60af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test split scores---\n",
      "nll=tensor(42595.9688)\n",
      "nll/n=tensor(2.1774)\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "log_likelihood = 0.0\n",
    "for w in test_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2,ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    ix1 = stoi2[ch1+ch2]\n",
    "    ix2 = stoi[ch3]\n",
    "    prob = P[ix1, ix2]\n",
    "    logprob = torch.log(prob)\n",
    "    log_likelihood += logprob\n",
    "    n += 1\n",
    "\n",
    "nll = -log_likelihood\n",
    "print(\"---Test split scores---\")\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ab97b-274e-48a0-8544-320909358817",
   "metadata": {},
   "source": [
    "For the trigram model, the scores are as expected - train loss is higher than dev and test loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6c9a7a-a952-40ff-817f-dc703f6a63f5",
   "metadata": {},
   "source": [
    "## Bigram using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db87c088-8f67-4d8a-a443-0e3026a3f94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364bf64a-1ece-4b60-b304-1b3a0c6bace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "for w in train_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2 in zip(chs,chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs)    \n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "# initialize neural net\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf3bf5bd-ee21-4f4a-b5e2-0a7a1ca1a056",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8041610717773438\n",
      "3.2413976192474365\n",
      "2.9880383014678955\n",
      "2.862083673477173\n",
      "2.784681558609009\n",
      "2.731771469116211\n",
      "2.692810535430908\n",
      "2.6631810665130615\n",
      "2.6398732662200928\n",
      "2.621373414993286\n",
      "2.606320858001709\n",
      "2.5940544605255127\n",
      "2.583772897720337\n",
      "2.5751562118530273\n",
      "2.5677032470703125\n",
      "2.5612969398498535\n",
      "2.5556116104125977\n",
      "2.5506350994110107\n",
      "2.546132802963257\n",
      "2.5421414375305176\n",
      "2.5384769439697266\n",
      "2.5351998805999756\n",
      "2.5321545600891113\n",
      "2.529414653778076\n",
      "2.5268430709838867\n",
      "2.524519205093384\n",
      "2.522320508956909\n",
      "2.5203280448913574\n",
      "2.5184288024902344\n",
      "2.516704559326172\n",
      "2.515050172805786\n",
      "2.513547658920288\n",
      "2.512096405029297\n",
      "2.5107784271240234\n",
      "2.509498119354248\n",
      "2.508335590362549\n",
      "2.50719952583313\n",
      "2.506169080734253\n",
      "2.5051567554473877\n",
      "2.504240036010742\n",
      "2.503333330154419\n",
      "2.502514600753784\n",
      "2.501699924468994\n",
      "2.5009658336639404\n",
      "2.5002312660217285\n",
      "2.499570846557617\n",
      "2.498906373977661\n",
      "2.4983110427856445\n",
      "2.4977076053619385\n",
      "2.497169017791748\n",
      "2.4966206550598145\n",
      "2.4961323738098145\n",
      "2.495631694793701\n",
      "2.495187759399414\n",
      "2.494729518890381\n",
      "2.494325876235962\n",
      "2.493905544281006\n",
      "2.493537187576294\n",
      "2.493150472640991\n",
      "2.4928138256073\n",
      "2.492457866668701\n",
      "2.4921493530273438\n",
      "2.491821050643921\n",
      "2.4915380477905273\n",
      "2.491234064102173\n",
      "2.490974187850952\n",
      "2.490692138671875\n",
      "2.4904537200927734\n",
      "2.490191698074341\n",
      "2.48997163772583\n",
      "2.4897282123565674\n",
      "2.489525079727173\n",
      "2.4892983436584473\n",
      "2.4891107082366943\n",
      "2.4888992309570312\n",
      "2.488725423812866\n",
      "2.488527774810791\n",
      "2.4883670806884766\n",
      "2.4881815910339355\n",
      "2.488032579421997\n",
      "2.487859010696411\n",
      "2.4877207279205322\n",
      "2.4875571727752686\n",
      "2.487429141998291\n",
      "2.4872751235961914\n",
      "2.4871559143066406\n",
      "2.487010955810547\n",
      "2.4869000911712646\n",
      "2.4867632389068604\n",
      "2.486659526824951\n",
      "2.4865305423736572\n",
      "2.486433982849121\n",
      "2.486311912536621\n",
      "2.4862220287323\n",
      "2.4861059188842773\n",
      "2.4860215187072754\n",
      "2.4859113693237305\n",
      "2.485833168029785\n",
      "2.4857285022735596\n",
      "2.485654830932617\n",
      "2.485555410385132\n",
      "2.4854862689971924\n",
      "2.485391855239868\n",
      "2.4853270053863525\n",
      "2.485236644744873\n",
      "2.4851763248443604\n",
      "2.4850897789001465\n",
      "2.4850335121154785\n",
      "2.484950065612793\n",
      "2.4848976135253906\n",
      "2.484818696975708\n",
      "2.4847683906555176\n",
      "2.4846928119659424\n",
      "2.4846456050872803\n",
      "2.4845733642578125\n",
      "2.4845290184020996\n",
      "2.484459400177002\n",
      "2.4844179153442383\n",
      "2.48435115814209\n",
      "2.484312057495117\n",
      "2.4842476844787598\n",
      "2.484210968017578\n",
      "2.4841489791870117\n",
      "2.4841148853302\n",
      "2.4840543270111084\n",
      "2.484022378921509\n",
      "2.483964681625366\n",
      "2.4839344024658203\n",
      "2.4838786125183105\n",
      "2.4838502407073975\n",
      "2.4837961196899414\n",
      "2.483769416809082\n",
      "2.483717203140259\n",
      "2.483692169189453\n",
      "2.4836413860321045\n",
      "2.4836182594299316\n",
      "2.4835691452026367\n",
      "2.4835469722747803\n",
      "2.483499526977539\n",
      "2.4834787845611572\n",
      "2.4834327697753906\n",
      "2.4834132194519043\n",
      "2.4833688735961914\n",
      "2.483350992202759\n",
      "2.483307361602783\n",
      "2.483290195465088\n",
      "2.483247995376587\n",
      "2.483231782913208\n",
      "2.4831912517547607\n",
      "2.4831762313842773\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for _ in range(150):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float()\n",
    "  logits = xenc @ W\n",
    "  counts = logits.exp()\n",
    "  probs = counts / counts.sum(1, keepdim=True)\n",
    "  loss = -probs[torch.arange(xs.nelement()), ys].log().mean() + 0.01*(W**2).mean()\n",
    "\n",
    "  print(loss.item())\n",
    "\n",
    "  # backward pass\n",
    "  W.grad = None\n",
    "  loss.backward()\n",
    "  with torch.no_grad():\n",
    "    W.data += -75 * W.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19857236-f4c5-4963-b2be-7583ecc89bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cfay.\n",
      "a.\n",
      "nn.\n",
      "kohin.\n",
      "tolia.\n",
      "s.\n",
      "tee.\n"
     ]
    }
   ],
   "source": [
    "# sampling from the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "    ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9643d62-65cb-477c-815c-e4c3175ed314",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7c8254b-4677-4c62-9849-b575b2bf24cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Train split scores---\n",
      "nll=tensor(2.4650, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27).float()\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "avg_log_likelihood = probs[torch.arange(xs.nelement()), ys].log().mean()\n",
    "      \n",
    "nll = -avg_log_likelihood\n",
    "print(\"---Train split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c80b52bc-fdda-4434-9e6d-3fb6e029dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Dev split scores---\n",
      "nll=tensor(2.4577, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dev_xs, dev_ys = [], []\n",
    "for w in dev_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2 in zip(chs,chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    dev_xs.append(ix1)\n",
    "    dev_ys.append(ix2)\n",
    "\n",
    "dev_xs = torch.tensor(dev_xs)    \n",
    "dev_ys = torch.tensor(dev_ys)\n",
    "\n",
    "xenc = F.one_hot(dev_xs, num_classes=27).float()\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "avg_log_likelihood = probs[torch.arange(dev_xs.nelement()), dev_ys].log().mean()\n",
    "      \n",
    "nll = -avg_log_likelihood\n",
    "print(\"---Dev split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f462e8e-b640-4408-aa40-0f638fb4320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Test split scores---\n",
      "nll=tensor(2.4678, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_xs, test_ys = [], []\n",
    "for w in test_words:\n",
    "  chs = [\".\"] + list(w) + [\".\"]\n",
    "  for ch1,ch2 in zip(chs,chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    test_xs.append(ix1)\n",
    "    test_ys.append(ix2)\n",
    "\n",
    "test_xs = torch.tensor(test_xs)    \n",
    "test_ys = torch.tensor(test_ys)\n",
    "\n",
    "xenc = F.one_hot(test_xs, num_classes=27).float()\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)\n",
    "avg_log_likelihood = probs[torch.arange(test_xs.nelement()), test_ys].log().mean()\n",
    "      \n",
    "nll = -avg_log_likelihood\n",
    "print(\"---Test split scores---\")\n",
    "print(f\"{nll=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e6949-3014-4f8a-bcb7-4e228e3cb45d",
   "metadata": {},
   "source": [
    "## Trigram using NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d59c23-73ce-4618-a793-ca46049ae338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e449461-6796-4e56-a13d-268b8fa4407a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1007ff-8255-46d5-8a12-1c005d6ef477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
