{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa83eae-1b6a-4f80-937b-e63fd0c8536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastcore.foundation import *\n",
    "from fastcore.basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f332b41-9e9d-4af0-9df9-f730739d9322",
   "metadata": {},
   "source": [
    "EX2: Train the GPT on your own dataset of choice! What other data could be fun to blabber on about? (A fun advanced suggestion if you like: train a GPT to do addition of two numbers, i.e. a+b=c. You may find it helpful to predict the digits of c in reverse order, as the typical addition algorithm (that you're hoping it learns) would proceed right to left too. You may want to modify the data loader to simply serve random problems and skip the generation of train.bin, val.bin. You may want to mask out the loss at the input positions of a+b that just specify the problem using y=-1 in the targets (see CrossEntropyLoss ignore_index). Does your Transformer learn to add? Once you have this, swole doge project: build a calculator clone in GPT, for all of +-*/. Not an easy problem. You may need Chain of Thought traces.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0ef0ec-f670-4501-82f5-0ddbd065d105",
   "metadata": {},
   "source": [
    "Example data:\n",
    "\n",
    "x: 9 8 7 1 . <br>\n",
    "y: 8 7 1 . ?\n",
    "\n",
    "x: 2 3 5 . ? <br>\n",
    "y: 3 5 . ? ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a90399-ca81-4f88-8986-de6495f4d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = torch.randint(0, 9, (1, )).item(), torch.randint(0, 9, (1, )).item()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2448d660-19ab-413f-92b4-c902976dece8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a+b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ebed79c-0130-4971-8e06-2517320ecb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c9753ce-f437-4479-954b-5335e34e5bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(list(reversed(str(c))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b8ad8e-e2d1-42c8-8784-4edf26c05256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'628.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pt = str(a) + str(b) + ''.join(list(reversed(str(c)))) + '.'\n",
    "data_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a873feb6-f026-4c15-8c6c-3a9682f21b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'628.?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_dtpt = data_pt\n",
    "while True:\n",
    "    if len(padded_dtpt) >= 5: break\n",
    "    padded_dtpt = padded_dtpt + '?'\n",
    "\n",
    "padded_dtpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5ae77fe-ded1-42d6-a1ab-40d7bafdc466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5]) tensor([0])\n",
      "tensor([5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 5,  0,  5, 10, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = torch.randint(0, 9, (1, )), torch.randint(0, 9, (1, ))\n",
    "print(a, b)\n",
    "c = a+b\n",
    "rev_c = list(reversed(str(c.item())))\n",
    "rev_c = torch.tensor([int(o) for o in rev_c])\n",
    "print(rev_c)\n",
    "out = torch.cat([a, b, rev_c, torch.tensor([10])], dim=-1)\n",
    "\n",
    "while len(out) < 5:\n",
    "    out = torch.cat([out, torch.tensor([11])], dim=-1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db9ac280-d2bc-4aec-aad9-27b6fa427fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5,  5, 10]), tensor([11,  5, 10, 11]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 -> '.' (end token)\n",
    "# 11 -> '?' (pad token)\n",
    "def _data_pt(blk_sz=5):\n",
    "    a, b = torch.randint(0, 9, (1, )), torch.randint(0, 9, (1, ))\n",
    "    c = a+b\n",
    "    rev_c = list(reversed(str(c.item())))\n",
    "    rev_c = torch.tensor([int(o) for o in rev_c])\n",
    "    out = torch.cat([a, b, rev_c, torch.tensor([10])])\n",
    "    while len(out) < blk_sz:\n",
    "        out = torch.cat([out, torch.tensor([11])])\n",
    "    x = out[:-1]\n",
    "    # copy to avoid changing the original tensor\n",
    "    y = out[1:].clone()\n",
    "    # first token should be pad token because we do not want to predict the input\n",
    "    y[0] = 11\n",
    "    return x, y\n",
    "\n",
    "data_pt = _data_pt()\n",
    "data_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8dbd1e-7c16-4141-a75c-deb1a00e4891",
   "metadata": {},
   "source": [
    "`nn.functional.cross_entropy` takes targets as class indices.\n",
    "\n",
    "At the places where we are just predicting the input tokens, we must mask them. Since, we are doing single digit addition, we can mask the inputs by taking the last input only when `T` < 2. ~~Now that I see it, we can also remove the need for a '?' padding token and just use 0 instead when we have single digit as the sum.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a5a356-3b7c-484f-b234-21367a27b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 0; Target: 11\n",
      "Input: 5; Target: 5\n",
      "Input: 5; Target: 10\n",
      "Input: 10; Target: 11\n"
     ]
    }
   ],
   "source": [
    "for t in range(4):\n",
    "    ctx = data_pt[0][t]\n",
    "    tgt = data_pt[1][t]\n",
    "    print(f\"Input: {ctx}; Target: {tgt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c79fddfa-3220-42eb-a537-25cdf7b6cad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5,  5, 10]), tensor([11,  5, 10, 11]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data_pt\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc8c56e-a582-496a-bd95-f1c8511c1ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([8, 7, 5, 1]), tensor([11,  5,  1, 10])),\n",
       " (tensor([ 4,  3,  7, 10]), tensor([11,  7, 10, 11])),\n",
       " (tensor([ 7,  1,  8, 10]), tensor([11,  8, 10, 11])),\n",
       " (tensor([ 5,  3,  8, 10]), tensor([11,  8, 10, 11])),\n",
       " (tensor([ 1,  5,  6, 10]), tensor([11,  6, 10, 11])),\n",
       " (tensor([ 1,  0,  1, 10]), tensor([11,  1, 10, 11])),\n",
       " (tensor([ 2,  6,  8, 10]), tensor([11,  8, 10, 11])),\n",
       " (tensor([ 2,  6,  8, 10]), tensor([11,  8, 10, 11]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sz = 8\n",
    "\n",
    "[_data_pt() for _ in range(batch_sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fc4032-7b90-4837-afaa-8db7c0b92bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2,  7,  9, 10],\n",
       "         [ 3,  6,  9, 10],\n",
       "         [ 1,  6,  7, 10],\n",
       "         [ 0,  7,  7, 10],\n",
       "         [ 8,  2,  0,  1],\n",
       "         [ 1,  8,  9, 10],\n",
       "         [ 7,  6,  3,  1],\n",
       "         [ 4,  1,  5, 10]]),\n",
       " tensor([[11,  9, 10, 11],\n",
       "         [11,  9, 10, 11],\n",
       "         [11,  7, 10, 11],\n",
       "         [11,  7, 10, 11],\n",
       "         [11,  0,  1, 10],\n",
       "         [11,  9, 10, 11],\n",
       "         [11,  3,  1, 10],\n",
       "         [11,  5, 10, 11]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = [_data_pt() for _ in range(batch_sz)]\n",
    "xb = torch.stack([o[0] for o in batch_data])\n",
    "yb = torch.stack([o[1] for o in batch_data])\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "459728bf-25d3-4c72-ba70-c813f333335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2,  2,  4, 10],\n",
       "         [ 8,  0,  8, 10],\n",
       "         [ 7,  2,  9, 10],\n",
       "         [ 0,  5,  5, 10],\n",
       "         [ 5,  8,  3,  1],\n",
       "         [ 3,  7,  0,  1],\n",
       "         [ 4,  8,  2,  1],\n",
       "         [ 2,  2,  4, 10]]),\n",
       " tensor([[11,  4, 10, 11],\n",
       "         [11,  8, 10, 11],\n",
       "         [11,  9, 10, 11],\n",
       "         [11,  5, 10, 11],\n",
       "         [11,  3,  1, 10],\n",
       "         [11,  0,  1, 10],\n",
       "         [11,  2,  1, 10],\n",
       "         [11,  4, 10, 11]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch():\n",
    "    batch_data = [_data_pt() for _ in range(batch_sz)]\n",
    "    xb = torch.stack([o[0] for o in batch_data])\n",
    "    yb = torch.stack([o[1] for o in batch_data])\n",
    "    return xb, yb\n",
    "\n",
    "get_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a436170-b6d0-4776-a121-fd7456540f71",
   "metadata": {},
   "source": [
    "All we need is that the llm take 7 2 and predict 9 and 0. We should \"ignore_index\" at the first position in `y` because that is the input digit and we do not want to penalize the model for not correctly predicting the input digit itself.\n",
    "\n",
    "In a batch, `targets` is of size `(B*T)`. Hence we must essentially replace the index at that position to a predetermined dummy index, aka, padding token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f18326b0-b547-4007-bfd7-65df324da480",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttn(nn.Module):\n",
    "    def __init__(self, head_sz, n_heads, n_embd, blk_sz):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "        self.attn = nn.Linear(n_embd, 3*n_embd)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones((blk_sz, blk_sz))))\n",
    "        self.proj = nn.Linear(n_embd, n_embd, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        # compute k,q,v at once and destructure it to have `n_embd` size\n",
    "        k,q,v = self.attn(x).split(self.n_embd, dim=-1)\n",
    "        # first view the tensors as (B, T, n_heads, head_sz), then transpose the middle dimensions to get (B, n_heads, T, head_sz).\n",
    "        # think about [T, n_heads] to be a separate matrix and think about transposing it.\n",
    "        # initially, you'll have T number of n_heads (have n_heads heads at each timestep) (T, n_heads)\n",
    "        # after transposing, you'll have, at each head, T \"blocks\" or timestep elements    (n_heads, T)\n",
    "        k = k.view(B, T, self.n_heads, self.head_sz).transpose(1, 2) # (B, n_heads, T, head_sz)\n",
    "        q = q.view(B, T, self.n_heads, self.head_sz).transpose(1, 2) # (B, n_heads, T, head_sz)\n",
    "        v = v.view(B, T, self.n_heads, self.head_sz).transpose(1, 2) # (B, n_heads, T, head_sz)\n",
    "        \n",
    "        # raw weights based on q, k affinity --> scaled dot product attn\n",
    "        wei = q @ k.transpose(-2, -1) * self.head_sz**-0.5 # (B, n_heads, T, head_sz) @ (B, n_heads, head_sz, T) --> (B, n_heads, T, T)\n",
    "        # mask past tokens and get a normalized distribution for affinities\n",
    "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf')) # (B, n_heads, T, T)\n",
    "        wei = wei.softmax(dim=-1) # (B, n_heads, T, T)\n",
    "        # scale value vector with affinities\n",
    "        out = wei @ v # (B, n_heads, T, T) @ (B, n_heads, T, head_sz) --> (B, n_heads, T, head_sz)\n",
    "        # transpose(1, 2) --> (B, T, n_heads, head_sz)\n",
    "        # contiguous --> transpose operations make the underlying memory non-contiguous. operations like view require contiguous memory representations.\n",
    "        # view --> (B, T, n_heads, head_sz) -> (B, T, n_embd) (n_embd = n_heads * head_sz)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, self.n_embd)\n",
    "        out = self.proj(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a273020f-ae6a-4667-bf59-78222cb588a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4*n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embd, n_embd),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "752c35ae-259b-4f75-948f-6a3f847333a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_heads, head_sz, blk_sz):\n",
    "        super().__init__()\n",
    "        store_attr()\n",
    "        self.causal_attn = CausalAttn(head_sz, n_heads, n_embd, blk_sz)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.causal_attn(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x # (B, T, n_embd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a36fd2f-c0e2-4ec0-9586-3412dd70d9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-9 + end_token(10) + padding_token(11) = 12\n",
    "vocab_sz = 12\n",
    "n_embd = 8\n",
    "blk_sz = 5\n",
    "n_heads = 2\n",
    "head_sz = n_embd // n_heads \n",
    "head_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16636ff-b1b9-424e-9224-00bbaac3a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb_table = nn.Embedding(vocab_sz, n_embd)\n",
    "        self.pos_emb_table = nn.Embedding(blk_sz, n_embd)\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(n_embd=n_embd, n_heads=n_heads, head_sz=head_sz, blk_sz=blk_sz),\n",
    "            Block(n_embd=n_embd, n_heads=n_heads, head_sz=head_sz, blk_sz=blk_sz),\n",
    "            nn.LayerNorm(n_embd)\n",
    "        )\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_sz)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B,T = idx.shape\n",
    "        tok_emb = self.tok_emb_table(idx)\n",
    "        pos_emb = self.pos_emb_table(torch.arange(T))\n",
    "\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None: loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.contiguous().view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets, ignore_index=11)\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbb0465b-b76a-4592-9b14-ce4d61978293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 4]), torch.Size([8, 4]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = AddGPT()\n",
    "xb, yb = get_batch()\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d15318dd-1c70-4952-9815-a76c4ace1d00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 12])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, _ = m(xb, yb)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5313a32a-1359-4013-92dd-be7adcb0002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AddGPT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6f1dfc9-25d9-44d4-9231-abd744826eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e782c74b-7709-4b60-854a-2658f553f8b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 2.768364429473877\n",
      "step 100: train loss 1.9739805459976196\n",
      "step 200: train loss 1.649142861366272\n",
      "step 300: train loss 1.3180294036865234\n",
      "step 400: train loss 1.06648588180542\n",
      "step 500: train loss 0.8726248741149902\n",
      "step 600: train loss 0.9190966486930847\n",
      "step 700: train loss 1.018977403640747\n",
      "step 800: train loss 0.8676979541778564\n",
      "step 900: train loss 0.8712950348854065\n",
      "step 1000: train loss 0.49270910024642944\n",
      "step 1100: train loss 0.5775040984153748\n",
      "step 1200: train loss 0.45224449038505554\n",
      "step 1300: train loss 0.5545138716697693\n",
      "step 1400: train loss 0.5130059719085693\n",
      "step 1500: train loss 0.420223593711853\n",
      "step 1600: train loss 0.4801110029220581\n",
      "step 1700: train loss 0.3629035949707031\n",
      "step 1800: train loss 0.31049254536628723\n",
      "step 1900: train loss 0.253854900598526\n",
      "step 2000: train loss 0.11121837049722672\n",
      "step 2100: train loss 0.10780270397663116\n",
      "step 2200: train loss 0.03641210123896599\n",
      "step 2300: train loss 0.04282999783754349\n",
      "step 2400: train loss 0.1906539350748062\n",
      "step 2500: train loss 0.07283464074134827\n",
      "step 2600: train loss 0.03343469649553299\n",
      "step 2700: train loss 0.04455380141735077\n",
      "step 2800: train loss 0.017963271588087082\n",
      "step 2900: train loss 0.05456977337598801\n",
      "step 3000: train loss 0.016750743612647057\n",
      "step 3100: train loss 0.010568896308541298\n",
      "step 3200: train loss 0.01326889730989933\n",
      "step 3300: train loss 0.009508713148534298\n",
      "step 3400: train loss 0.009737036190927029\n",
      "step 3500: train loss 0.00697074132040143\n",
      "step 3600: train loss 0.008995052427053452\n",
      "step 3700: train loss 0.007018931210041046\n",
      "step 3800: train loss 0.005545908585190773\n",
      "step 3900: train loss 0.005883369594812393\n",
      "step 4000: train loss 0.004525929689407349\n",
      "step 4100: train loss 0.004377858713269234\n",
      "step 4200: train loss 0.004027791786938906\n",
      "step 4300: train loss 0.0046791089698672295\n",
      "step 4400: train loss 0.0034806188195943832\n",
      "step 4500: train loss 0.003886989550665021\n",
      "step 4600: train loss 0.0688745528459549\n",
      "step 4700: train loss 0.03946452960371971\n",
      "step 4800: train loss 0.007889410480856895\n",
      "step 4900: train loss 0.00742663349956274\n",
      "step 5000: train loss 0.00967419520020485\n",
      "step 5100: train loss 0.004508832935243845\n",
      "step 5200: train loss 0.003446804126724601\n",
      "step 5300: train loss 0.003448957111686468\n",
      "step 5400: train loss 0.0031755995005369186\n",
      "step 5500: train loss 0.004274971783161163\n",
      "step 5600: train loss 0.003676862455904484\n",
      "step 5700: train loss 0.0031068981625139713\n",
      "step 5800: train loss 0.002411660272628069\n",
      "step 5900: train loss 0.002334986347705126\n",
      "step 6000: train loss 0.00306740147061646\n",
      "step 6100: train loss 0.002616272773593664\n",
      "step 6200: train loss 0.0019055599113926291\n",
      "step 6300: train loss 0.0016836700960993767\n",
      "step 6400: train loss 0.0016045287484303117\n",
      "step 6500: train loss 0.0016940009081736207\n",
      "step 6600: train loss 0.001645354088395834\n",
      "step 6700: train loss 0.0015889499336481094\n",
      "step 6800: train loss 0.0015672174049541354\n",
      "step 6900: train loss 0.001237070420756936\n"
     ]
    }
   ],
   "source": [
    "for i in range(7000):\n",
    "    xb, yb = get_batch()\n",
    "    \n",
    "    logits, loss = model(xb, yb)\n",
    "    optim.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    if i % 100 == 0: print(f\"step {i}: train loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97bfcf48-b7ae-4314-93a3-1ea4605202bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.tensor([[2, 3]])\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41146478-f301-44de-bd68-72d7aaff8f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 12])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits, loss = model(inp)\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a1336df-cd8e-4a22-9680-7e45bcf87f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:, -1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d83c968-1ba2-4e5f-9c4b-da664e75c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = logits[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8de15a24-abf2-4a3d-8cbe-e96410869f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0652e-04, 3.7571e-09, 6.6792e-05, 3.3451e-06, 3.0085e-04, 9.9867e-01,\n",
       "         1.3629e-04, 4.6625e-05, 4.9033e-05, 1.9042e-06, 4.9086e-04, 3.2574e-05]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4f3a3a2-c452-469b-97c2-be3dd449e8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43023a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 9]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = torch.tensor([[9, 9]])\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2105a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits,_ = model(ctx)\n",
    "    logits = logits[:, -1, :]\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "318960bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0043e-05, 8.9165e-02, 1.6099e-04, 4.8151e-07, 1.2751e-05, 6.6755e-08,\n",
       "         1.4713e-05, 1.1228e-08, 1.9014e-06, 3.7309e-06, 9.1059e-01, 1.6245e-05]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "289d28db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d797925f-1119-4b66-80f1-adb15a364fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8,  8,  6,  1, 10]])\n",
      "tensor([[ 1,  2,  3, 10]])\n",
      "tensor([[ 4,  5,  9, 10]])\n",
      "tensor([[ 6,  7,  3,  1, 10]])\n",
      "tensor([[ 9,  0,  1, 10]])\n",
      "tensor([[ 9,  9, 10]])\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def add(a, b):\n",
    "    ctx = torch.tensor([[a, b]])\n",
    "    while ctx[0, -1] != 10:\n",
    "        logits, _ = model(ctx)\n",
    "        logits = logits[:, -1, :] # B, T, C -> B, C (selects the last timestep)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_tok = torch.argmax(probs).unsqueeze(0).unsqueeze(0) # 0 dimensional -> 2 dimensional\n",
    "        ctx = torch.cat([ctx, next_tok], dim=-1)\n",
    "\n",
    "    return ctx\n",
    "\n",
    "print(add(8, 8))\n",
    "print(add(1, 2))\n",
    "print(add(4, 5))\n",
    "print(add(6, 7))\n",
    "print(add(9, 0))\n",
    "print(add(9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7eb73c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 + 1 = tensor([1])\n",
      "0 + 2 = tensor([2])\n",
      "0 + 3 = tensor([3])\n",
      "0 + 4 = tensor([4])\n",
      "0 + 5 = tensor([5])\n",
      "0 + 6 = tensor([6])\n",
      "0 + 7 = tensor([7])\n",
      "0 + 8 = tensor([8])\n",
      "1 + 2 = tensor([3])\n",
      "1 + 3 = tensor([4])\n",
      "1 + 4 = tensor([5])\n",
      "1 + 5 = tensor([6])\n",
      "1 + 6 = tensor([7])\n",
      "1 + 7 = tensor([8])\n",
      "1 + 8 = tensor([9])\n",
      "2 + 3 = tensor([5])\n",
      "2 + 4 = tensor([6])\n",
      "2 + 5 = tensor([7])\n",
      "2 + 6 = tensor([8])\n",
      "2 + 7 = tensor([9])\n",
      "2 + 8 = tensor([0, 1])\n",
      "3 + 4 = tensor([7])\n",
      "3 + 5 = tensor([8])\n",
      "3 + 6 = tensor([9])\n",
      "3 + 7 = tensor([0, 1])\n",
      "3 + 8 = tensor([1, 1])\n",
      "4 + 5 = tensor([9])\n",
      "4 + 6 = tensor([0, 1])\n",
      "4 + 7 = tensor([1, 1])\n",
      "4 + 8 = tensor([2, 1])\n",
      "5 + 6 = tensor([1, 1])\n",
      "5 + 7 = tensor([2, 1])\n",
      "5 + 8 = tensor([3, 1])\n",
      "6 + 7 = tensor([3, 1])\n",
      "6 + 8 = tensor([4, 1])\n",
      "7 + 8 = tensor([5, 1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for j in range(i+1, 10):\n",
    "        if i == 9 or j == 9: continue\n",
    "        print(f\"{i} + {j} = {add(i, j)[0][2:-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6134b45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 + 0 = tensor([1])\n",
      "2 + 0 = tensor([2])\n",
      "3 + 0 = tensor([3])\n",
      "4 + 0 = tensor([4])\n",
      "5 + 0 = tensor([5])\n",
      "6 + 0 = tensor([6])\n",
      "7 + 0 = tensor([7])\n",
      "8 + 0 = tensor([8])\n",
      "2 + 1 = tensor([3])\n",
      "3 + 1 = tensor([4])\n",
      "4 + 1 = tensor([5])\n",
      "5 + 1 = tensor([6])\n",
      "6 + 1 = tensor([7])\n",
      "7 + 1 = tensor([8])\n",
      "8 + 1 = tensor([9])\n",
      "3 + 2 = tensor([5])\n",
      "4 + 2 = tensor([6])\n",
      "5 + 2 = tensor([7])\n",
      "6 + 2 = tensor([8])\n",
      "7 + 2 = tensor([9])\n",
      "8 + 2 = tensor([0, 1])\n",
      "4 + 3 = tensor([7])\n",
      "5 + 3 = tensor([8])\n",
      "6 + 3 = tensor([9])\n",
      "7 + 3 = tensor([0, 1])\n",
      "8 + 3 = tensor([1, 1])\n",
      "5 + 4 = tensor([9])\n",
      "6 + 4 = tensor([0, 1])\n",
      "7 + 4 = tensor([1, 1])\n",
      "8 + 4 = tensor([2, 1])\n",
      "6 + 5 = tensor([1, 1])\n",
      "7 + 5 = tensor([2, 1])\n",
      "8 + 5 = tensor([3, 1])\n",
      "7 + 6 = tensor([3, 1])\n",
      "8 + 6 = tensor([4, 1])\n",
      "8 + 7 = tensor([5, 1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for j in range(i+1, 10):\n",
    "        if i == 9 or j == 9: continue\n",
    "        print(f\"{j} + {i} = {add(j, i)[0][2:-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27fab118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 + 9 = tensor([ 0,  9, 10])\n",
      "1 + 9 = tensor([ 1,  9, 10])\n",
      "2 + 9 = tensor([ 2,  9, 10])\n",
      "3 + 9 = tensor([ 3,  9,  3, 10])\n",
      "4 + 9 = tensor([ 4,  9,  1, 10])\n",
      "5 + 9 = tensor([ 5,  9,  3, 10])\n",
      "6 + 9 = tensor([ 6,  9,  1, 10])\n",
      "7 + 9 = tensor([ 7,  9,  8, 10])\n",
      "8 + 9 = tensor([ 8,  9, 10])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for j in range(i+1, 10):\n",
    "        if i != 9 and j != 9: continue\n",
    "        print(f\"{i} + {j} = {add(i, j)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd9d0e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  9,  3, 10]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(3, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee43a540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
